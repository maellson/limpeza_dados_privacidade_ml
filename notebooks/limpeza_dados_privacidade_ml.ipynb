{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook: Limpeza de Dados Pessoais para Projetos de Machine Learning (Conformidade LGPD, PL 2338, ANPD e NIST)\n",
    "\n",
    "\"\"\"\n",
    "Este notebook apresenta um fluxo completo e profissional para a detecção, anonimização e remoção de dados pessoais em conformidade com normas regulatórias:\n",
    "\n",
    "- LGPD (Lei 13.709/2018)\n",
    "- PL 2338/2023\n",
    "- Diretrizes da ANPD\n",
    "- NIST Privacy Framework\n",
    "\n",
    "**Objetivo:** Utilizar técnicas baseadas em LLM (Large Language Models), SQLAlchemy e Pandas para:\n",
    "- Detectar dados pessoais não apenas por nomes de colunas, mas pelo conteúdo das células\n",
    "- Automatizar o descarte, anonimização ou substituição de campos sensíveis\n",
    "- Garantir a privacidade e segurança de dados na fase de EDA em projetos de Machine Learning\n",
    "\n",
    "Este processo respeita os princípios da minimização, necessidade, finalidade e transparência conforme a LGPD.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Conectar ao banco e listar tabelas\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('postgresql://usuario:senha@host:porta/banco')\n",
    "inspector = inspect(engine)\n",
    "tabelas = inspector.get_table_names()\n",
    "print(\"Tabelas disponíveis:\", tabelas)\n",
    "\n",
    "# 2. Função para carregar e inspecionar os primeiros registros\n",
    "AMOSTRA = 100\n",
    "\n",
    "def carregar_tabela(tabela):\n",
    "    query = f\"SELECT * FROM {tabela} LIMIT {AMOSTRA}\"\n",
    "    return pd.read_sql_query(query, con=engine)\n",
    "\n",
    "# 3. Detecção Inteligente com LLM (simulação)\n",
    "\"\"\"\n",
    "Aqui você pode usar uma API de LLM como OpenAI, Mistral, Claude, etc.\n",
    "Para cada coluna da tabela, analisamos os 100 primeiros valores e pedimos à LLM que classifique se o conteúdo se refere a dados pessoais (nome, CPF, telefone, etc).\n",
    "\"\"\"\n",
    "from openai import OpenAI\n",
    "\n",
    "# Simulação (ajuste com sua chave e endpoint)\n",
    "# openai.api_key = \"sua-chave\"\n",
    "\n",
    "# Detectar colunas sensíveis\n",
    "import random\n",
    "\n",
    "def simular_identificacao_llm(df):\n",
    "    sensiveis = []\n",
    "    for col in df.columns:\n",
    "        exemplo = df[col].dropna().astype(str).sample(min(5, len(df))).tolist()\n",
    "        prompt = f\"\"\"\n",
    "        Diga se a seguinte lista de dados representa informações pessoais identificáveis sob a LGPD. \n",
    "        Dados: {exemplo} \n",
    "        Se sim, retorne 'sensível', caso contrário 'não'.\n",
    "        \"\"\"\n",
    "        # Aqui seria a chamada real:\n",
    "        # response = openai.ChatCompletion.create(...)\n",
    "        # Simulação de resposta (em produção, substitua pela API):\n",
    "        if any('email' in val or '@' in val or '-' in val for val in exemplo):\n",
    "            sensiveis.append(col)\n",
    "    return sensiveis\n",
    "\n",
    "# 4. Processo Completo por Tabela\n",
    "\n",
    "base_final = {}\n",
    "\n",
    "for tabela in tabelas:\n",
    "    df = carregar_tabela(tabela)\n",
    "    print(f\"\\nProcessando tabela: {tabela} (linhas: {len(df)}, colunas: {len(df.columns)})\")\n",
    "    colunas_sensiveis = simular_identificacao_llm(df)\n",
    "\n",
    "    print(f\"Colunas sensíveis detectadas: {colunas_sensiveis}\")\n",
    "    df_limpo = df.drop(columns=colunas_sensiveis)\n",
    "\n",
    "    base_final[tabela] = df_limpo\n",
    "    print(f\"Tabela '{tabela}' limpa e pronta para EDA com {df_limpo.shape[1]} colunas.\")\n",
    "\n",
    "# 5. Justificativa e Conformidade\n",
    "\"\"\"\n",
    "Cada passo foi projetado com base em princípios legais e boas práticas:\n",
    "\n",
    "- **Identificação de dados sensíveis via conteúdo:** muitos campos podem estar mal rotulados (ex: \"contato1\" conter CPF ou e-mail).\n",
    "- **Limpeza antes do uso:** garante que modelos de ML não sejam treinados indevidamente com dados pessoais, evitando vazamentos e infrações legais.\n",
    "- **LLM como ferramenta de apoio:** traz inteligência contextual para além da regex ou validações manuais.\n",
    "\n",
    "Este processo pode ser registrado via logs para auditoria, e validado junto à equipe jurídica e de compliance.\n",
    "\"\"\"\n",
    "\n",
    "# 6. Próximos Passos (recomendados)\n",
    "\"\"\"\n",
    "- Integrar com ferramenta de lineage e rastreamento (como Great Expectations ou SodaSQL)\n",
    "- Documentar o dicionário de dados com marcação de sensibilidade\n",
    "- Versão em produção deve anonimizar ao invés de excluir (para manter consistência de schema)\n",
    "- LLMs podem ser refinados com exemplos específicos do seu domínio\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
